# Pitfalls Research: v2.1 Assessment Resilience & Real-Time Monitoring

**Domain:** ASP.NET Core MVC — Adding auto-save, session resume, worker exam polling, and HC live monitoring to an existing exam system

**Researched:** 2026-02-24

**Confidence:** HIGH — based on direct codebase analysis (CMPController SaveAnswer/CheckExamStatus implementation, existing polling at 30s intervals, EF Core migrations, PackageUserResponse persistence pattern, timer and navigation patterns in StartExam.cshtml)

---

## Executive Summary

Adding four interconnected features to an existing monolithic exam system introduces race conditions, idempotency failures, database migration timing issues, and data consistency gaps. The existing codebase already has a polling mechanism (`CheckExamStatus` at 30s intervals, Phase 39-02) and incremental answer saving (`SaveAnswer` for auto-save, upsert pattern), but integrating them with session resume (LastPageIndex + ElapsedSeconds columns), live monitoring endpoints (answered-count per user), and page navigation (Prev/Next firing overlapping AJAX requests) creates three classes of problems:

1. **Race Conditions:** Overlapping auto-save, page navigation, and final submit requests can corrupt or duplicate answer records
2. **Data Consistency:** EF migration timing, nullable column semantics, and upsert logic must align across three persistence paths (auto-save, page navigation save, final submit)
3. **Integration Pitfalls:** Antiforgery tokens on SaveAnswer conflict with stateless monitoring GET requests; polling interval tuning (30s vs 10s) affects both worker experience and database load; UI state (answered count, page index, elapsed time) must stay synchronized with server state

---

## Critical Pitfalls

### Pitfall 1: Race Condition Between Auto-Save and Page Navigation

**What goes wrong:**
When a worker clicks a radio button, auto-save fires an AJAX POST to `SaveAnswer`. Before that request completes, the worker clicks "Next Page", which executes `changePage()` JavaScript. The `changePage()` function updates `currentPage` and re-renders the UI, but does not wait for the pending `SaveAnswer` request to finish. If the network is slow or the server is under load, two overlapping requests can both write to `PackageUserResponses` for the same (sessionId, questionId) pair:

1. Auto-save request: AJAX POST SaveAnswer (sessionId, q1, optionA) — reaches DB at T1
2. Page navigation: Happens immediately at T1+50ms (network latency), no save triggered
3. BUT: If user clicks the same question again before navigating to next page, a second auto-save fires
4. Result: Two rapid SaveAnswer requests for the same question can cause duplicate upserts or race the write-update-read cycle, leaving stale values in PackageUserResponses.SubmittedAt or PackageOptionId

This is particularly dangerous in the upsert logic of SaveAnswer:
```csharp
var existing = await _context.PackageUserResponses
    .FirstOrDefaultAsync(r => r.AssessmentSessionId == sessionId && r.PackageQuestionId == questionId);
if (existing != null) {
    existing.PackageOptionId = optionId;  // <-- Two threads can both find same record, both update, one wins
    existing.SubmittedAt = DateTime.UtcNow;
}
```

**Why it happens:**
The code assumes each SaveAnswer request completes before the next one starts. In reality, browser AJAX is non-blocking; JavaScript continues executing `changePage()` while the previous fetch is in-flight. The worker's network condition, server response time, and click speed are all non-deterministic. At corporate networks with 200-500ms latency spikes, overlapping requests are common.

**Consequences:**
- Duplicate or stale SubmittedAt timestamps in the database (audit trail shows wrong times)
- LiveMonitoring endpoint reads answered count incorrectly (returns stale data from wrong SubmittedAt)
- Session resume loads wrong LastPageIndex or ElapsedSeconds if the previous page's answer is still in-flight when the next page saves
- No visible error to the worker — the form still submits, but the audit trail is corrupted

**Prevention:**
1. **Debounce auto-save:** Track a pending request flag. If a second SaveAnswer fires before the first completes, queue it and only fire the second after the first responds.
   ```javascript
   let savePending = false;
   function saveAnswerAsync(questionId, optionId) {
       if (savePending) {
           // Queue this request; process after current completes
           return;
       }
       savePending = true;
       fetch(...).then(...).finally(() => { savePending = false; });
   }
   ```

2. **Lock page navigation during auto-save:** Disable the Next/Previous buttons until all pending auto-save requests complete.
   ```javascript
   function changePage(newPage) {
       if (savePending) {
           alert('Saving answer... please wait.');
           return;
       }
       // ... proceed with changePage
   }
   ```

3. **Server-side request deduplication:** Add a request ID (UUID) to each SaveAnswer call. If two requests with the same (sessionId, questionId, requestId) arrive, the second is rejected with "already processed."

4. **Optimistic locking on PackageUserResponse:** Add a `Version` column (EF Core RowVersion). If two updates conflict, the second fails with a concurrency exception, which the client can catch and retry.

**Detection:**
- HC monitoring dashboard shows a user with answered count = 11 but the answered-time column has duplicate timestamps for the same question (SubmittedAt = 10:22:45 appears twice)
- Worker's final submission is accepted but their resume data (LastPageIndex) is off by one page (saved before auto-save from previous page finished)
- Audit logs show SaveAnswer calls arriving at T1 and T1+50ms for the same question ID

**Phase to address:** Phase 35 (auto-save feature itself) must include debouncing and request blocking. Cannot be added as a follow-up patch without rework.

---

### Pitfall 2: Session Resume Loads Last Saved Page, Not Current Page When Auto-Save is Pending

**What goes wrong:**
The session resume feature adds `LastPageIndex` and `ElapsedSeconds` columns to `AssessmentSession`. On page navigation (Prev/Next), the code is supposed to save these values:

```csharp
// In CMPController, StartExam or similar action
session.LastPageIndex = currentPageIndex;  // derived from query string or model
session.ElapsedSeconds = (DateTime.UtcNow - session.StartedAt).TotalSeconds;
await _context.SaveChangesAsync();
```

But when is this code triggered? If it's in a separate endpoint (not SaveAnswer), and the worker navigates quickly:

1. Worker on page 1, clicks radio for Q1 → SaveAnswer auto-fire (T0)
2. Worker immediately clicks "Next Page" (T0+20ms) → assumes changePage() saves LastPageIndex in the same SaveAnswer request (WRONG)
3. Worker's browser crashes or loses connection (T0+100ms)
4. Worker refreshes browser, returns to exam
5. StartExam loads session from DB, reads `LastPageIndex = 0` (still page 1, because SaveAnswer only saved the answer, not the page index)
6. Worker re-answers Q1 and navigates to page 2 again

The bug is that SaveAnswer saves the answer but does NOT save page navigation state. If page navigation updates are in a separate synchronous call or rely on the browser sending an additional request (which may never happen), the resume state is inconsistent.

**Why it happens:**
The feature was designed without thinking through the full save flow. SaveAnswer is fire-and-forget for answers only. Page navigation state (which questions are on which page, where the worker was) is orthogonal to answer persistence. No single endpoint captures both.

**Consequences:**
- Worker resumes and re-answers questions already answered on earlier pages
- Duplicate answer entries in the database if resume + auto-save both save the same question
- Time-elapsed calculation is wrong (shows less time than actually used, since resume starts from old LastPageIndex)
- Worker confusion: "Why is my score lower? I already answered this!"

**Prevention:**
1. **Include page index in SaveAnswer:** Modify SaveAnswer signature to accept `pageIndex` and save it to `session.LastPageIndex` in the same request.
   ```csharp
   public async Task<IActionResult> SaveAnswer(int sessionId, int questionId, int optionId, int pageIndex)
   {
       var session = await _context.AssessmentSessions.FindAsync(sessionId);
       session.LastPageIndex = pageIndex;  // Track page navigation
       // ... save answer, save changes
   }
   ```

2. **OR: Add a separate endpoint for page navigation state:**
   ```csharp
   [HttpPost]
   public async Task<IActionResult> SavePageNavigation(int sessionId, int pageIndex)
   {
       // Lightweight call to update LastPageIndex and ElapsedSeconds
   }
   // Call from changePage() before rendering the new page
   ```

3. **Server-side validation on resume:** When loading LastPageIndex, verify all questions from page 0 to LastPageIndex-1 have been answered. If not, reject resume and reset to page 0.
   ```csharp
   // On StartExam, if resuming:
   var allAnswered = await _context.PackageUserResponses
       .Where(r => r.AssessmentSessionId == sessionId)
       .Select(r => r.PackageQuestionId)
       .ToListAsync();
   if (!allAnsweredUpToPreviousPage) {
       session.LastPageIndex = 0;  // Reset to start
   }
   ```

**Detection:**
- Worker resumes exam, page shows questions they already answered earlier (re-answering scenario)
- Answered-count in HC monitoring dashboard fluctuates downward (duplicates are being counted, then removed)
- Database query shows multiple PackageUserResponse records for the same (sessionId, questionId) with different SubmittedAt timestamps within seconds of each other

**Phase to address:** Phase 35 (auto-save and SaveAnswer must include page index in the same request) OR Phase 36 (if session resume is added after auto-save, it must validate the consistency and potentially reset).

---

### Pitfall 3: EF Migration for LastPageIndex and ElapsedSeconds Breaks Existing Sessions

**What goes wrong:**
When the migration adds `LastPageIndex INT NOT NULL` and `ElapsedSeconds INT NOT NULL` to the `AssessmentSessions` table, existing in-progress sessions have null or garbage values. If the migration uses `.HasDefaultValue(0)` on the database:

```csharp
protected override void Up(MigrationBuilder migrationBuilder) {
    migrationBuilder.AddColumn<int>(
        name: "LastPageIndex",
        table: "AssessmentSessions",
        type: "int",
        nullable: false,
        defaultValue: 0);
}
```

Then all existing rows get `LastPageIndex = 0` and `ElapsedSeconds = 0`. When a worker who started an exam before the migration resumes:

1. Migration runs, existing in-progress session gets LastPageIndex = 0, ElapsedSeconds = 0
2. Worker refreshes browser, session was paused at page 3 (from client-side state)
3. StartExam loads session, reads `LastPageIndex = 0`, resets worker to page 0
4. Worker confused: "My page was saved locally, why am I back at the start?"
5. If client-side state (from JS variables or localStorage) differs from server state, inconsistency surfaces

**Why it happens:**
The migration is deployed during business hours when workers are actively taking exams. The default value applies to all existing rows, not just new ones. There is no data migration script that calculates what the actual LastPageIndex should have been for paused sessions.

**Consequences:**
- Workers lose their place mid-exam
- If the client has cached the correct page in localStorage, there's a conflict between client state and server state
- Duplicate answer submissions if worker re-answers from page 0 thinking they are resuming
- Support burden: workers call HC saying "my exam was reset"

**Prevention:**
1. **Add columns as nullable first:**
   ```csharp
   migrationBuilder.AddColumn<int?>(
       name: "LastPageIndex",
       table: "AssessmentSessions",
       nullable: true);
   migrationBuilder.AddColumn<int?>(
       name: "ElapsedSeconds",
       table: "AssessmentSessions",
       nullable: true);
   ```
   Then in the code, treat null as "not resumed yet" and default to page 0.

2. **OR: Deploy with BackfillMigration:**
   - First migration: add columns as nullable
   - Deploy and run
   - Second migration: run a data migration script that calculates actual page index for paused sessions (e.g., based on answered question count)
   - Third migration: add NOT NULL constraint

3. **OR: Two-stage rollout:**
   - v2.1-A: Deploy code that WRITES to the new columns but still works without them (reads existing state from client)
   - Wait 24 hours for any in-flight sessions to complete naturally
   - v2.1-B: Deploy migration, now safe because no in-flight sessions exist

**Detection:**
- Workers report being reset to page 0 after migration
- Multiple complaint tickets on the same day migration was deployed
- Database query shows sessions with `LastPageIndex = 0` but `CreatedAt` is 1 week ago and `StartedAt` is 6 hours ago (old session, should have had a page value)

**Phase to address:** Phase 35 (migrations must be planned with zero-downtime in mind). Must include a backfill script or nullable-first approach.

---

### Pitfall 4: LiveMonitoring Endpoint Exposes Worker Email or NIP in Real-Time Dashboard

**What goes wrong:**
The new HC monitoring endpoint (Phase 39) returns answered-count per user:

```csharp
[HttpGet]
public async Task<IActionResult> GetLiveMonitoringData()
{
    var sessions = await _context.AssessmentSessions
        .Where(s => s.Status == "InProgress")
        .Include(s => s.User)
        .ToListAsync();

    var data = sessions.Select(s => new {
        userId = s.UserId,
        userName = s.User.FullName,  // OK
        userEmail = s.User.Email,    // POTENTIALLY EXPOSED IF CALLED FROM CLIENT
        answeredCount = /* query PackageUserResponses */
    });

    return Json(data);
}
```

If this endpoint is called from the HC JavaScript dashboard (JS refreshing every 5-10s), it executes in the browser with the HC user's identity. The response JSON contains all live user data. If the response is logged (browser console, error tracking services like Sentry), or cached unencrypted, worker PII (email, full name) is visible in production logs.

Additionally, if the endpoint is not properly authorized with `[Authorize(Roles = "Admin, HC")]`, any authenticated user (including a Coach or Coachee) can call it and see all workers' real-time activity.

**Why it happens:**
The feature was designed to show live progress to HC staff. The developer included user identification fields to help HC understand who is taking what exam. They forgot that JSON responses in JavaScript are visible in browser history, error traces, and third-party logging services.

**Consequences:**
- Worker PII (email) visible in HC's browser console if they inspect network requests
- PII leaks to error tracking services if the fetch fails and is logged with full request/response
- If HC shares a screenshot of the monitoring dashboard, worker emails are visible
- Compliance violation: PII exposed beyond necessary scope (HC needs to know *how many* workers are in progress, not necessarily their email addresses)

**Prevention:**
1. **Never return email/NIP in the response.** Use userId only for identification internally, or return a sanitized ID:
   ```csharp
   var data = sessions.Select(s => new {
       sessionId = s.Id,  // Safe identifier
       userName = s.User.FullName,  // OK — less sensitive
       answeredCount = /* ... */
   });
   ```

2. **Add explicit authorization:**
   ```csharp
   [HttpGet]
   [Authorize(Roles = "Admin, HC")]
   public async Task<IActionResult> GetLiveMonitoringData()
   ```

3. **Exclude sensitive fields from the ViewModel:**
   ```csharp
   var data = sessions.Select(s => new LiveMonitoringDto {
       SessionId = s.Id,
       WorkerName = s.User.FullName,
       // Do NOT include Email, NIP, Phone, etc.
   }).ToList();
   ```

4. **Test the endpoint as a Coachee-role user** to verify it returns 403.

**Detection:**
- Browser DevTools Network tab shows GetLiveMonitoringData response containing email addresses
- Error tracking service logs show PII in JSON responses
- Compliance audit discovers email in monitoring endpoint response

**Phase to address:** Phase 39 (live monitoring endpoint design). Must be reviewed by security/compliance before implementation. Add to code review checklist: "Does the response expose unnecessary PII?"

---

### Pitfall 5: Polling Interval Mismatch Between Worker Status Check (30s) and HC Live Monitoring (5-10s)

**What goes wrong:**
The existing `CheckExamStatus` endpoint (Phase 39-02) is polled by worker JavaScript every 30 seconds to detect early exam close by HC. The new HC live monitoring dashboard (Phase 39) polls `GetLiveMonitoringData` every 5-10 seconds to refresh answered counts.

Two problems:

1. **Data freshness inconsistency:** If a worker answers a question at T0, SaveAnswer writes to the DB immediately. But `GetLiveMonitoringData` might return stale answered-count if it caches results or runs a slow query. The HC dashboard shows "Worker has answered 5 questions" but CheckExamStatus on the worker side might still show "4 questions answered" (client-side state hasn't updated yet). HC and the worker are looking at different versions of reality.

2. **Database load:** A 10-second poll interval from 50 HC users simultaneously = 5 queries/second on GetLiveMonitoringData. If the query is complex (JOINs with Include, GROUP BY, etc.), the database can spike. If there are 500 in-progress exams, each query must scan all 500 sessions and count PackageUserResponses for each. This becomes O(n) per query, 5 times per second, 50 concurrent users = potential database saturation.

**Why it happens:**
The two features (worker status polling and HC live monitoring) were designed independently. No conversation happened about query patterns or polling intervals. The 30-second interval was chosen for worker polling to minimize database load (they expect 100-200 workers). The 5-10 second interval for HC dashboard feels like good UX (live updates for HC), without calculating the amplified database impact.

**Consequences:**
- HC sees stale answered-count (shows 3 when actual is 4, by the time HC reads it)
- Database CPU spikes during busy exam windows (morning of exam day, all workers start simultaneously)
- Worker experience degrades if database load causes query timeouts on CheckExamStatus (workers see "failed to detect exam close")
- LiveMonitoring endpoint returns 500 error during load, HC dashboard breaks

**Prevention:**
1. **Increase HC polling interval to 15-30 seconds:**
   ```javascript
   // In HC live monitoring JS
   setInterval(function() {
       fetch('/CMP/GetLiveMonitoringData')
           .then(resp => resp.json())
           .then(data => updateDashboard(data));
   }, 30000);  // 30 seconds, not 5-10
   ```
   Justification: HC doesn't need to see updates every 5 seconds; 30 seconds is acceptable for admin dashboards.

2. **Optimize the query for live monitoring:**
   ```csharp
   // Use a materialized view or cached summary table
   var summary = await _context.LiveExamSummary
       .FromSqlInterpolated($"SELECT SessionId, UserId, AnsweredCount FROM vw_LiveExamSummary")
       .ToListAsync();
   // vw_LiveExamSummary is maintained by a trigger or scheduled job, not computed on-demand
   ```

3. **Add caching with short TTL:**
   ```csharp
   var key = "live_monitoring_data";
   if (!_cache.TryGetValue(key, out var cachedData)) {
       cachedData = /* compute full data */;
       _cache.Set(key, cachedData, TimeSpan.FromSeconds(10));
   }
   return Json(cachedData);
   ```
   HC sees data that's at most 10 seconds stale, reducing query load.

4. **Document the polling interval choice in code:**
   ```javascript
   // Poll every 30 seconds (standard for admin dashboards; 5-10s causes DB saturation)
   setInterval(checkExamStatus, 30000);
   ```

**Detection:**
- Database query logs show GetLiveMonitoringData consuming 50-100ms per execution during busy exams
- HC dashboard noticeably stutters or becomes unresponsive during concurrent exam load
- Application Insights shows query timeout errors on GetLiveMonitoringData
- Worker experiences "failed to check exam status" messages (timeout on CheckExamStatus during database load spike)

**Phase to address:** Phase 39 (live monitoring design phase) must include database impact analysis. Run load tests with 100+ concurrent in-progress exams and measure query time at different polling intervals.

---

### Pitfall 6: Antiforgery Token Missing on CheckExamStatus GET Request Causes 400 or Misclassification

**What goes wrong:**
The existing `CheckExamStatus` endpoint in the codebase is a GET request (no antiforgery token required):

```csharp
[HttpGet]
public async Task<IActionResult> CheckExamStatus(int sessionId)
{
    // No [ValidateAntiForgeryToken] — it's a safe, read-only GET
}
```

This is correct for a read-only status check. However, when live monitoring (`GetLiveMonitoringData`) is added, a developer might mistakenly:

1. Copy the SaveAnswer pattern (which uses `[ValidateAntiForgeryToken]`)
2. Add the token validation to GetLiveMonitoringData
3. But forget to include the token in the AJAX call from the HC dashboard JavaScript

Result: GetLiveMonitoringData endpoint expects `__RequestVerificationToken` in the request, but the HC dashboard JavaScript doesn't include it (because it's a GET request, and tokens are usually only needed for POST). The request gets a 400 Bad Request or the token validation silently fails.

Alternatively, the developer forgets to add the `[ValidateAntiForgeryToken]` attribute to a POST endpoint that should have it (e.g., if SavePageNavigation is added as a POST but token validation is forgotten). This creates a CSRF vulnerability.

**Why it happens:**
Misunderstanding of antiforgery token rules: GET requests don't need tokens (they're safe), POST requests do. Copy-paste errors when adding new endpoints. No standardized pattern in the codebase for which endpoints require tokens (SaveAnswer has it, CheckExamStatus doesn't).

**Consequences:**
- HC monitoring dashboard breaks with 400 errors when trying to fetch live data
- Developers disable token validation on a POST endpoint to "fix" the error, unknowingly introducing CSRF vulnerability
- New endpoints added without proper token handling due to unclear patterns

**Prevention:**
1. **Document the pattern:** Add a comment in the controller:
   ```csharp
   // ========== AUTHENTICATION PATTERN ==========
   // GET endpoints (read-only): No [ValidateAntiForgeryToken]
   // POST endpoints (modify state): MUST have [ValidateAntiForgeryToken]
   // Exceptions:
   //   - CheckExamStatus is GET (read-only, no token needed)
   //   - SaveAnswer is POST (modifies PackageUserResponse, token required)
   //   - GetLiveMonitoringData is GET (read-only, no token needed)
   ```

2. **Add token validation selectively:** Only on POST/PUT/DELETE that modify state:
   ```csharp
   [HttpPost]  // Modifies state
   [ValidateAntiForgeryToken]
   public async Task<IActionResult> SaveAnswer(int sessionId, int questionId, int optionId)
   ```

   ```csharp
   [HttpGet]   // Read-only
   [Authorize(Roles = "Admin, HC")]
   public async Task<IActionResult> GetLiveMonitoringData()
   // NO token validation needed
   ```

3. **Use a code analyzer or EditorConfig rule** to enforce token validation on all non-GET endpoints (if available in your toolchain).

4. **Test the endpoint before deployment:** Call GetLiveMonitoringData from the HC dashboard in a test environment and verify no 400 errors occur.

**Detection:**
- HC monitoring dashboard shows network error (400 Bad Request) in DevTools
- Application Insights shows 400 errors on GetLiveMonitoringData endpoint
- Developers report "the new live monitoring feature returns 400 when I call it from JS"

**Phase to address:** Phase 39 (live monitoring) and Phase 35 (auto-save). Every new HTTP endpoint must have explicit antiforgery token strategy documented and tested.

---

### Pitfall 7: SubmitExam and Auto-Save Create Duplicate Answer Records if Both Run Near Completion

**What goes wrong:**
The existing SubmitExam endpoint loops through all questions and calls `_context.PackageUserResponses.Add()` for each answer:

```csharp
foreach (var q in packageQuestions) {
    // ... fetch selectedOptId from answers dict ...
    var existingResponse = await _context.PackageUserResponses
        .FirstOrDefaultAsync(r => r.AssessmentSessionId == id && r.PackageQuestionId == q.Id);
    if (existingResponse != null) {
        existingResponse.PackageOptionId = selectedOptId;
    } else {
        _context.PackageUserResponses.Add(new PackageUserResponse { /* ... */ });
    }
}
```

This upsert logic assumes SaveAnswer has already written records for all (or most) questions. But if a worker navigates to the final "Review and Submit" page without clicking on some questions (because they use pre-filled answers or localStorage), SaveAnswer never fires for those questions. SubmitExam correctly adds them.

HOWEVER, if SaveAnswer and SubmitExam both run for the same question in rapid succession (worker is on the last question, clicks radio to select an answer, immediately hits Submit button while the SaveAnswer fetch is still in-flight):

1. Worker on page N, Q10, clicks radio for option A → SaveAnswer AJAX fires
2. Worker clicks "Review and Submit" → SubmitExam form POST fires
3. SaveAnswer request completes at T1: inserts new PackageUserResponse (Q10, optionA)
4. SubmitExam POST arrives at T1+20ms, reads answers dict, runs upsert:
   - Query: is there a response for Q10? YES (just inserted by SaveAnswer)
   - Update: existingResponse.PackageOptionId = answers[Q10]
5. PROBLEM: SubmitExam commits to the session AFTER the upsert loop, but SaveAnswer already committed. If there's any discrepancy in how the answer is parsed (e.g., optionId is sent as int vs string in one request), the final SubmittedAt timestamp might be wrong.

Additionally, the upsert in SubmitExam re-reads the database:
```csharp
var existingResponse = await _context.PackageUserResponses
    .FirstOrDefaultAsync(r => r.AssessmentSessionId == id && r.PackageQuestionId == q.Id);
```

If SaveAnswer and SubmitExam both execute their upsert loops concurrently, they might both call FirstOrDefaultAsync at the same time, both find no record, both insert — creating a duplicate.

**Why it happens:**
The two code paths (auto-save and final submit) were designed separately, with the assumption that one completes before the other. The upsert logic in each is correct in isolation but not atomic when both are running. EF Core's change tracking doesn't prevent duplicate inserts if two parallel requests load the same entity.

**Consequences:**
- PackageUserResponse table has duplicate rows for the same (sessionId, questionId)
- Results page reads duplicates, shows confusing answer history
- Audit log is incorrect (timestamp, count of answers)
- Database reports "multiple answers for question 10" when correcting scores manually

**Prevention:**
1. **Disable the final-submit Save loop if auto-save is enabled:**
   ```csharp
   // In SubmitExam, check if answers are already in the database
   var autoSaveEnabled = true;  // Feature flag or constant
   if (autoSaveEnabled) {
       // Don't re-save answers; they're already in the database via SaveAnswer
       // Just calculate the score from existing PackageUserResponses
       var savedResponses = await _context.PackageUserResponses
           .Where(r => r.AssessmentSessionId == id)
           .ToListAsync();
       // ... calculate score from savedResponses ...
   } else {
       // Legacy path: no auto-save, so SubmitExam must save all answers
       foreach (var q in packageQuestions) { /* upsert */ }
   }
   ```

2. **Add a database constraint to prevent duplicates:**
   ```csharp
   // In OnModelCreating
   builder.Entity<PackageUserResponse>(entity => {
       entity.HasIndex(r => new { r.AssessmentSessionId, r.PackageQuestionId })
           .IsUnique();  // One answer per question per session
   });
   ```
   Then wrap upsert in a try-catch for `DbUpdateException` (unique constraint violation).

3. **OR: Use a database transaction with isolation level SERIALIZABLE:**
   ```csharp
   using (var transaction = await _context.Database.BeginTransactionAsync(IsolationLevel.Serializable)) {
       var existing = await _context.PackageUserResponses.FirstOrDefaultAsync(...);
       // ... upsert ...
       await _context.SaveChangesAsync();
       await transaction.CommitAsync();
   }
   ```
   (Warning: this can cause deadlocks under high concurrency; use with caution.)

4. **OR: Client-side guard — disable Submit button until all pending SaveAnswer requests complete:**
   ```javascript
   let savePending = 0;
   function saveAnswerAsync(questionId, optionId) {
       savePending++;
       fetch(...).finally(() => {
           savePending--;
           updateSubmitButtonState();
       });
   }
   function updateSubmitButtonState() {
       document.getElementById('reviewSubmitBtn').disabled = (savePending > 0);
   }
   ```

**Detection:**
- Database query reveals multiple PackageUserResponse rows with the same (sessionId, packageQuestionId):
  ```sql
  SELECT SessionId, PackageQuestionId, COUNT(*)
  FROM PackageUserResponses
  GROUP BY SessionId, PackageQuestionId
  HAVING COUNT(*) > 1
  ```
- Results page shows multiple answer entries for the same question
- Audit log timestamps show near-simultaneous SaveAnswer and SubmitExam entries for the same question

**Phase to address:** Phase 35 (auto-save) and Phase 36 (when it integrates with SubmitExam). Must add duplicate prevention before feature is live.

---

### Pitfall 8: Polling Doesn't Survive Browser Crashes — Session Never Marks as "Paused" or "Abandoned"

**What goes wrong:**
The worker exam polling (`CheckExamStatus` every 30s) runs in the browser. If the worker's browser crashes, loses network connection, or closes the tab, the polling loop stops. The server never receives the stop signal. The session remains in "InProgress" status indefinitely.

When HC runs a query to find active exams for a quick status report, they see sessions marked "InProgress" from 3 hours ago (actually crashed, worker has moved on). This is a data consistency issue and impacts analytics.

Additionally, if a worker crashes during an exam and reopens the browser 10 minutes later, StartExam loads the session as "InProgress" and allows resume. The worker re-answers questions thinking they're resuming. But the timer has been counting down in the database (or was frozen at crash time), so the elapsed time is inconsistent with the worker's subjective experience.

**Why it happens:**
Polling is a client-initiated, one-way communication. The server cannot detect when the client disappears (browser crash, force-close) unless the client explicitly sends a signal. TCP connections can take 10+ minutes to time out. Without explicit heartbeat or cleanup logic, orphaned sessions accumulate.

**Consequences:**
- HC dashboard shows fake "in progress" sessions that are actually abandoned
- Worker analytics are skewed (average exam duration appears longer because abandoned sessions are counted)
- Worker confusion: resume shows timer at 5 minutes remaining, but subjectively they just started
- Support burden: worker calls saying "the timer is wrong"

**Prevention:**
1. **Add a HeartBeat endpoint that worker polling sends periodically:**
   ```csharp
   [HttpPost]
   public async Task<IActionResult> SendHeartbeat(int sessionId) {
       var session = await _context.AssessmentSessions.FindAsync(sessionId);
       session.LastHeartbeatAt = DateTime.UtcNow;  // New column
       await _context.SaveChangesAsync();
       return Json(new { success = true });
   }
   ```

   ```javascript
   setInterval(function() {
       // Send heartbeat
       fetch('/CMP/SendHeartbeat?sessionId=' + SESSION_ID).catch(() => {});
   }, 60000);  // Every 60 seconds
   ```

   Then in a background job or cleanup script:
   ```csharp
   // Every 5 minutes, mark sessions with no heartbeat in 10 minutes as "Abandoned"
   var orphanedSessions = await _context.AssessmentSessions
       .Where(s => s.Status == "InProgress" &&
                   (s.LastHeartbeatAt == null || DateTime.UtcNow.Subtract(s.LastHeartbeatAt.Value).TotalMinutes > 10))
       .ToListAsync();
   foreach (var session in orphanedSessions) {
       session.Status = "Abandoned";
       session.UpdatedAt = DateTime.UtcNow;
   }
   await _context.SaveChangesAsync();
   ```

2. **OR: Add a client-side onbeforeunload handler to signal abandon:**
   ```javascript
   window.addEventListener('beforeunload', function() {
       // Send synchronous XHR (deprecated but works for cleanup)
       // or just accept that some sessions will be orphaned
       navigator.sendBeacon('/CMP/AbandonExam?sessionId=' + SESSION_ID);
   });
   ```

3. **Set a server-side timeout:** Sessions in "InProgress" for longer than 2x the exam duration are auto-marked as "Abandoned" by a scheduled job.

**Detection:**
- HC monitoring dashboard shows sessions in "InProgress" for 6+ hours (human-impossible exam duration)
- Analysis: "Most workers complete exams in 45 minutes; we have 20 sessions in 'InProgress' for 8 hours"
- Worker reports: "I took the exam 2 hours ago, why does the timer still show 5 minutes remaining when I resume?"

**Phase to address:** Phase 36 (session resume must handle abandoned sessions) or Phase 39 (polling logic should include heartbeat). Cannot be an afterthought; must be in the design.

---

## Moderate Pitfalls

### Pitfall 9: ElapsedSeconds Calculation Drifts if Clocks are Out of Sync

**What goes wrong:**
`ElapsedSeconds` is calculated on the server as `(DateTime.UtcNow - session.StartedAt).TotalSeconds`. If the server's clock is out of sync with the worker's clock (which is common in corporate networks with NTP drift), the time calculation becomes inaccurate.

For example:
- Server clock is 2 minutes behind worker's clock
- Worker sees 58 minutes remaining (timer = 120s - elapsed)
- Server calculates ElapsedSeconds and persists = (UtcNow - StartedAt) = 58 minutes from server perspective
- But actually, 60 minutes have passed from worker perspective
- On resume, worker see "58 minutes remaining" but already used 62 actual minutes

The timer in the view is client-side (counts down from `DURATION_SECONDS` on the browser), so the discrepancy only appears in the database `ElapsedSeconds` column and resume scenarios.

**Why it happens:**
NTP is not perfect; even corporate networks can have 30-second to 2-minute drifts. The code assumes server and client clocks are synchronized.

**Prevention:**
1. **Don't use ElapsedSeconds for timer logic; use it only for audit.** The actual timer is client-side in the JavaScript. Persist it only for record-keeping, not for resume logic.

2. **OR: Include client timestamp in SaveAnswer:**
   ```javascript
   var clientTimestamp = Date.now();  // Client's clock
   fetch(..., {
       body: 'clientTimestamp=' + clientTimestamp + '&...'
   });
   ```
   Then on the server:
   ```csharp
   var clientTime = long.Parse(HttpContext.Request.Form["clientTimestamp"]);
   var clientTimestampUtc = new DateTime(clientTime, DateTimeKind.Utc);
   session.ElapsedSeconds = (int)(clientTimestampUtc - session.StartedAt).TotalSeconds;
   ```

3. **OR: Accept a 10% tolerance in time validation.** If the timer is off by up to 10%, consider it acceptable; don't fail the exam.

**Detection:**
- Worker resumes exam, timer shows a different value than what they remember
- ElapsedSeconds in the database is noticeably different from (CompletedAt - StartedAt)

**Phase to address:** Phase 35 (decide early: use client time or accept server time discrepancies). Document the choice in code.

---

### Pitfall 10: HC Monitoring Endpoint Returns Stale Data if Queries Run Slow

**What goes wrong:**
The GetLiveMonitoringData endpoint runs a query like:

```csharp
var sessions = await _context.AssessmentSessions
    .Where(s => s.Status == "InProgress")
    .Include(s => s.User)
    .ToListAsync();

var data = sessions.Select(s => new {
    answeredCount = _context.PackageUserResponses
        .Count(r => r.AssessmentSessionId == s.Id)
});
```

This is N+1: one query to get sessions, then N queries (one per session) to count answered questions. If there are 50 in-progress sessions, this is 51 queries. If each takes 50ms, total time is 2.5 seconds.

If HC's browser polls every 10 seconds and the server takes 2.5 seconds to respond, only 1 in 4 polls succeeds before the next poll is sent. The browser's fetch queue fills up, responses are delayed, and the dashboard shows data from 10-30 seconds ago.

**Prevention:**
1. **Use a GROUP BY query to fetch answered counts in one shot:**
   ```csharp
   var answeredCounts = await _context.PackageUserResponses
       .Where(r => sessions.Select(s => s.Id).Contains(r.AssessmentSessionId))
       .GroupBy(r => r.AssessmentSessionId)
       .Select(g => new { SessionId = g.Key, Count = g.Count() })
       .ToListAsync();
   ```

2. **Cache the result with a 10-second TTL** (see Pitfall 5).

3. **Use a materialized view** if your database supports it.

**Detection:**
- HC monitoring dashboard is slow to update (takes 5-10 seconds for an answer to appear)
- Browser DevTools shows multiple overlapping GetLiveMonitoringData requests (one every 10s, but the previous one hasn't completed)

**Phase to address:** Phase 39 (query must be optimized before deployment).

---

## Integration Gotchas

| Integration | Common Mistake | Correct Approach |
|-------------|----------------|------------------|
| Auto-save + Page navigation | Assume SaveAnswer completes before next page loads | Debounce SaveAnswer; disable Next/Prev buttons until all pending saves complete |
| Session resume + Auto-save | Save answer but not page index | Include pageIndex in SaveAnswer, or use separate SavePageNavigation endpoint |
| EF migration + In-progress sessions | Add NOT NULL columns with defaultValue | Add columns as nullable first; handle null in code as "not yet resumed" |
| LiveMonitoring + SubmitExam | Both read answered-count; counts diverge | Use cache or materialized view to ensure consistent answered-count source |
| CheckExamStatus polling + Browser crash | No signal sent when browser closes | Add heartbeat endpoint; mark sessions as "Abandoned" if no heartbeat for 10+ minutes |
| Antiforgery tokens + GET requests | Assume all new endpoints need token validation | Document pattern: GET (no token), POST (require token); review all endpoints before merge |
| SaveAnswer + SubmitExam upserts | Both run concurrently, creating duplicates | Disable SubmitExam upsert loop if auto-save enabled; OR add unique constraint on (sessionId, questionId) |
| Client timer + ElapsedSeconds | Server and client clocks drift | Use client timestamp in SaveAnswer; or accept tolerance; or don't use ElapsedSeconds for resume logic |

---

## Phase-Specific Prevention Checklist

### Phase 35: Auto-Save Feature

- [ ] **Debounce auto-save:** Implement request queuing so overlapping SaveAnswer calls don't create duplicates
- [ ] **Disable navigation during auto-save:** Next/Prev buttons disabled until all pending saves complete
- [ ] **Include pageIndex in SaveAnswer:** Save the page the answer was answered on, not just the answer itself
- [ ] **Test race condition:** Rapidly click radio and then Next Page; verify database has only one response per question
- [ ] **Database unique constraint:** Add unique index on (AssessmentSessionId, PackageQuestionId) to prevent accidental duplicates
- [ ] **Antiforgery token review:** Verify SaveAnswer has [ValidateAntiForgeryToken]; verify no other endpoints accidentally require it
- [ ] **Test partial completion:** Answer questions 1-5, skip 6-10, hit Submit; verify SubmitExam doesn't create duplicates

### Phase 36: Session Resume

- [ ] **EF Migration plan:** Add columns as nullable; do NOT add NOT NULL until second migration after one release cycle
- [ ] **Resume validation:** When loading LastPageIndex, verify consistency with answered questions; reset to 0 if invalid
- [ ] **Heartbeat endpoint:** Add SendHeartbeat (POST) for workers and cleanup job to mark abandoned sessions
- [ ] **Test resume after crash:** Kill browser mid-exam, reload, resume; verify lastPageIndex and ElapsedSeconds are accurate
- [ ] **Test migration on in-progress sessions:** During test migration, verify in-progress sessions still work and don't get reset
- [ ] **Backward compatibility:** Ensure code handles NULL values for ElapsedSeconds and LastPageIndex (from pre-migration sessions)

### Phase 39: Live Monitoring

- [ ] **Endpoint authorization:** Add [Authorize(Roles = "Admin, HC")] to GetLiveMonitoringData; test as Coachee user (expect 403)
- [ ] **PII audit:** Verify response does NOT include Email, NIP, or other sensitive fields
- [ ] **Query optimization:** Use GROUP BY for answered-count; measure query time with 100+ concurrent sessions
- [ ] **Polling interval:** Set to 30s or use caching with 10s TTL; load-test before deployment
- [ ] **Antiforgery token:** Verify GetLiveMonitoringData is GET (no token needed) or POST (token included in HC JS)
- [ ] **Cache strategy:** Decide on cache TTL and implement if query is slow
- [ ] **Database load test:** Simulate 50 HC users polling every 10s; verify database CPU stays below 50%

---

## Data Consistency Rules (Must Not Break)

| Invariant | Why It Matters | How to Maintain |
|-----------|---|---|
| One PackageUserResponse per (SessionId, QuestionId) | Answers are unique; no duplication in results | Unique database constraint; prevent double-save in SaveAnswer and SubmitExam |
| LastPageIndex ≤ TotalPages | Resume doesn't load a non-existent page | Validate in code before using; reset to 0 if invalid |
| ElapsedSeconds ≤ DurationMinutes * 60 + 120 | Timer doesn't show negative time on resume | Validate on load; if invalid, reset to 0 |
| Session.Status transitions: null → "InProgress" → "Completed" OR "Abandoned" | No sessions stuck in invalid states | Heartbeat cleanup job; explicit status checks in each endpoint |
| SaveAnswer only succeeds if Session.Status == "InProgress" | No answers saved after exam closed | Check status in SaveAnswer; return error if not InProgress |
| SubmitExam only succeeds if Session.Status == "InProgress" AND elapsed time ≤ DurationMinutes + 2 min | No submissions after time limit | Validate both conditions in SubmitExam |

---

## Recovery Strategies

| Pitfall | Recovery Time | Recovery Steps |
|---------|---|---|
| Duplicate PackageUserResponse rows in DB | MEDIUM | Identify duplicates with GROUP BY query; delete older records or merge timestamps; verify submitted answers match intent |
| In-progress sessions reset to page 0 after migration | MEDIUM | Revert migration (if possible); redeploy without NOT NULL constraint; OR manually update affected sessions with correct LastPageIndex based on answered question count |
| HC monitoring dashboard 400 errors | LOW | Add RequestVerificationToken to fetch in HC JS, or confirm endpoint is GET (no token needed); test endpoint in browser console |
| LiveMonitoring exposes PII | HIGH | Remove Email/NIP from response immediately; redeploy hotfix; audit logs for any leaks; notify compliance |
| Database saturation from polling | MEDIUM | Increase polling interval to 30s; add caching; run queries during off-hours to rebuild indexes; OR add database read replica for monitoring queries |
| Session stuck in "InProgress" for hours | MEDIUM | Run manual cleanup script: mark sessions older than 2x duration as "Abandoned"; verify no active workers affected |

---

## "Looks Done But Isn't" Checklist for Phases 35-36-39

- [ ] **Auto-save requests are debounced:** Rapid clicks on radio don't create duplicate requests
- [ ] **Page navigation waits for auto-save:** Next/Prev buttons disabled during pending SaveAnswer
- [ ] **Unique constraint added to PackageUserResponse:** (SessionId, QuestionId) is unique; prevents accidental duplicates
- [ ] **EF migration for new columns is nullable-first:** LastPageIndex and ElapsedSeconds allow NULL; code handles NULL as "0" or "not resumed"
- [ ] **Heartbeat mechanism implemented:** Worker sends heartbeat every 60s; abandoned sessions cleaned up every 5 minutes
- [ ] **HC authorization on monitoring endpoint:** GetLiveMonitoringData returns 403 for non-HC roles; tested with Coachee user
- [ ] **PII audit complete:** Response JSON contains NO Email, NIP, Phone, Address — only safe identifiers (SessionId, FullName)
- [ ] **Query optimized:** GetLiveMonitoringData runs in <500ms with 100 concurrent sessions; uses GROUP BY, not N+1 loop
- [ ] **Polling interval documented:** Code comment explains why 30s was chosen; load test results attached to PR
- [ ] **Antiforgery token strategy documented:** Comments show which endpoints require tokens; all POST have tokens, all GET do not
- [ ] **Resume validation in code:** LastPageIndex is checked; reset to 0 if out of bounds or inconsistent with answered questions
- [ ] **Timer and elapsed-time logic separate:** Client-side timer (JavaScript) runs independently; ElapsedSeconds used only for audit, not resume logic
- [ ] **All new endpoints manually tested with different roles:** At least Admin, HC, Coachee; verify 200 or 403 as appropriate
- [ ] **Database migration tested on live-like dataset:** Run migration on a database with 50+ in-progress sessions; verify no data loss, no reset to page 0

---

## Sources

- **SaveAnswer implementation:** `Controllers/CMPController.cs` lines 1033-1071, including upsert pattern, antiforgery token, authorization checks
- **CheckExamStatus implementation:** `Controllers/CMPController.cs` lines 1075-1102, including 30s polling interval in `StartExam.cshtml` line 346
- **SubmitExam implementation:** `Controllers/CMPController.cs` lines 3161-3305, including upsert loop for PackageUserResponse, competency updates, legacy path
- **StartExam view with auto-save JavaScript:** `Views/CMP/StartExam.cshtml` lines 163-347, including:
  - Timer countdown (lines 185-204)
  - Page navigation function (lines 208-215)
  - Auto-save on radio change (lines 224-252, fire-and-forget pattern)
  - CheckExamStatus polling (lines 314-346)
- **AssessmentSession model:** `Models/AssessmentSession.cs` (no LastPageIndex or ElapsedSeconds columns yet; must be added by migration)
- **ApplicationDbContext:** `Data/ApplicationDbContext.cs` lines 85-108, showing existing AssessmentSession configuration, indexes, and constraints
- **Existing polling implementation:** Phase 39-02 mentions 30s poll interval from v1.7; confirmed in StartExam.cshtml line 346

---

## Notes for v2.1 Roadmap

**Phase ordering rationale:**
1. **Phase 35 (Auto-save)** must come before Phase 36 (session resume), because resume data is populated BY auto-save (LastPageIndex needs to be set during page navigation, which happens during auto-save flow)
2. **Phase 36 (Session Resume)** can run parallel with Phase 39 (Live Monitoring), but must coordinate on migration timing: both may need EF Core migrations; must deploy in sequence (resume first, because it adds the resume columns)
3. **Phase 39 (Live Monitoring)** depends on no new critical bugs in Phase 35-36, since it adds polling load to the already-complex exam flow

**Critical risks flagged for deeper research:**
- **Race condition between SaveAnswer and SubmitExam:** Must implement unique constraint AND debouncing before Phase 35 ships
- **Migration timing with in-progress sessions:** Run migration test with >50 concurrent sessions in progress; consider two-stage rollout
- **Database load from live monitoring:** Must load-test GetLiveMonitoringData with 100+ concurrent sessions at different polling intervals before Phase 39 ships

---

*Pitfalls research for: Portal HC KPB — v2.1 Assessment Resilience & Real-Time Monitoring*

*Researched: 2026-02-24*
